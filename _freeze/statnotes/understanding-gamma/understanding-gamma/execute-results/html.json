{
  "hash": "233b24640a95669cfcb3ebc04966c3ed",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Understanding (hopefully) the Gamma distribution\nauthor: Filippo Gambarota\nformat:\n    html:\n        code-fold: false\n        code-summary: \"Show the code\"\n---\n\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ngamma_params <- function(shape = NULL, scale = 1/rate, rate = 1,\n                         mean = NULL, sd = NULL,\n                         eqs = FALSE){\n  if(eqs){\n    cat(rep(\"=\", 25), \"\\n\")\n    cat(eqs()$gamma, \"\\n\")\n    cat(rep(\"=\", 25), \"\\n\")\n  }else{\n      if(is.null(shape)){\n      var <- sd^2\n      shape <- mean^2 / var\n      scale <- mean / shape\n      rate <- 1/scale\n    } else if(is.null(mean) & is.null(sd)){\n      if(is.null(rate)){\n        scale <- 1/rate\n      } else{\n        rate <- 1/scale\n      }\n      mean <- shape * scale\n      var <- shape * scale^2\n      sd <- sqrt(var)\n    }else{\n      stop(\"when shape and scale are provided, mean and sd need to be NULL (and viceversa)\")\n    }\n    out <- list(shape = shape, scale = scale, rate = rate, mean = mean, var = var, sd = sd)\n    # coefficient of variation\n    out$cv <- 1/sqrt(shape)\n    return(out)\n  }\n}\n\ngammap <- function(mean = NULL,\n                   sd = NULL,\n                   shape = NULL,\n                   scale = NULL,\n                   rate = NULL,\n                   skew = NULL,\n                   cv = NULL){\n    pars <- as.list(environment())\n    spars <- pars[!sapply(pars, is.null)]\n    \n    is_pair <- function(x, pair){\n        all(x %in% pair)\n    }\n    \n    compute <- function(shape, scale) {\n        rate <- 1 / scale\n        mean <- shape * scale\n        sd <- sqrt(shape * scale^2)\n        cv <- 1 / sqrt(shape)\n        skew <- 2 / sqrt(shape)\n        list(shape = shape, rate = rate, scale = scale, cv = cv, skew = skew, mean = mean, sd = sd)\n    }\n    \n    if(is_pair(names(spars), c(\"mean\", \"sd\"))){\n        mean <- spars$mean\n        sd <- spars$sd\n        cv <- sd/mean\n        shape <- 1 / cv^2\n        scale <- mean / shape\n    } else if(is_pair(names(spars), c(\"mean\", \"shape\"))){\n        mean <- spars$mean\n        shape <- spars$shape\n        scale <- mean / shape\n    } else if(is_pair(names(spars), c(\"mean\", \"cv\"))){\n        mean <- spars$mean\n        cv <- spars$cv\n        shape <- 1 / cv^2\n        scale <- mean * cv^2\n    } else if(is_pair(names(spars), c(\"shape\", \"rate\"))){\n        shape <- spars$shape\n        scale <- 1/spars$rate\n    }else if(is_pair(names(spars), c(\"shape\", \"scale\"))){\n        shape <- spars$shape\n        scale <- spars$scale\n    } else{\n        stop(\"combination not implemented!\")\n    }\n    \n    compute(shape, scale)\n    \n}\n\nggamma <- function(shape = NULL,\n                   scale = 1/rate,\n                   rate = 1,\n                   mean = NULL,\n                   sd = NULL,\n                   show = c(\"msd\", \"sr\", \"ss\"),\n                   lf = 5,\n                   size = 15,\n                   ns = 1e4){\n  show <- match.arg(show)\n  argg <- as.list(environment())[1:5]\n  gm <- do.call(gamma_params, argg)\n  if(length(unique(sapply(gm, length))) != 1){\n    stop(\"All vectors need to be of the same length!\")\n  }\n\n  n <- length(gm$mean)\n  range <- c(0, max(gm$mean) + lf * max(gm$sd))\n  x <- seq(range[1], range[2], length.out = ns)\n  d <- mapply(function(sh, sc) dgamma(x, shape = sh, scale = sc), gm$shape, gm$scale, SIMPLIFY = FALSE)\n  D <- data.frame(x = rep(x, n),\n                  d = unlist(d),\n                  shape = rep(gm$shape, each = length(x)),\n                  scale = rep(gm$scale, each = length(x)),\n                  rate = rep(gm$rate, each = length(x)),\n                  mean = rep(gm$mean, each = length(x)),\n                  sd = rep(gm$sd, each = length(x))\n  )\n\n  if(show == \"msd\"){\n    D$cond <- factor(sprintf(\"$\\\\mu = %.3f$, $\\\\sigma = %.3f$\", D$mean, D$sd))\n  }else if(show == \"ss\"){\n    D$cond <- factor(sprintf(\"$k (shape) = %.3f$, $\\\\theta (scale) = %.3f$\", D$shape, D$scale))\n  }else{\n    D$cond <- factor(sprintf(\"$\\\\alpha (shape) = %.3f$, $\\\\beta (rate) = %.3f$\", D$shape, D$rate))\n  }\n\n  ggplot(D, aes(x = x, y = d, color = cond)) +\n    geom_line(lwd = 1) +\n    scale_color_discrete(labels = lapply(levels(D$cond), latex2exp::TeX)) +\n    theme_minimal(15) +\n    theme(legend.title = element_blank(),\n          legend.position = c(.95, .95),\n          legend.justification = c(\"right\", \"top\"),\n          legend.box.just = \"right\",\n          legend.margin = margin(6, 6, 6, 6)\n    ) +\n    ylab(latex2exp::TeX(\"dgamma($x$, $\\\\alpha$/$k$, $\\\\theta$, $\\\\beta$)\"))\n}\n```\n:::\n\n\n\n\n# Gamma, Poisson and Exponential\n\nBefore the **Gamma** distribution, we can start briefly introducing the **Poisson** and **Exponential** distribution because they are strictly linked.\n\nWe can make a little spoiler about the link and then going into details:\n\n> The Poisson distribution represents the rate of discrete events for a fixed period of time (unit time). The exponential distribution is the time that it takes for the first event to happen while the Gamma distribution represents the time taken by $k$ events to happen.\n\nIn fact, even without going into details about the equations, is not a coincidence that all three distributions have one parameter called the rate (usually $\\lambda$).\n\n## Poisson distribution\n\nThe poisson distribution PMF (probability mass function) is represented in @eq-poisson-pmf.\n\n$$\nP(X = k) = \\frac{\\lambda^k e^{-\\lambda}}{k!}\n$${#eq-poisson-pmf}\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlambda <- 10\nx <- seq(0, 30, 1)\n\nggplot(data = data.frame(x)) +\n    geom_segment(aes(x = x, xend = x, y = 0, yend = dpois(x, lambda))) +\n    ggtitle(tex(\"\\\\lambda = 10\"))\n```\n\n::: {.cell-output-display}\n![](understanding-gamma_files/figure-html/unnamed-chunk-3-1.svg){fig-align='center' width=672}\n:::\n:::\n\n\n\n\nThe mean if the poisson is just $\\lambda$ and the variance is still $\\lambda$ (thus the standard deviaton is $\\sqrt{\\lambda}$). This is also very intuitive because as $\\lambda$ decrease, the spread of the distribution decrease because there it is left-bounded on zero. This is a common feature of Exponential, Gamma and Poisson distributions.\n\nAn assumption of the Poisson distribution is that $\\lambda$ is fixed for every observation and this is the most common limitation that often (if not always) lead to overdispersion, but this is another story.\n\nAs a practical example, let's assume that we are observing the number of cars passing on a certain street during 1 hour. 1 hour is our unit time and $\\lambda$ is the average number of cars i.e. the average rate of cars. \n\n## Exponential distribution\n\nThe exponential distribution is a continous probability distribution that describe the time taken for the first event of a Poisson process to happen.\n\n$$\nf(x; \\lambda) = \\lambda e^{-\\lambda x}, \\quad x \\geq 0\n$$\n\nThe only parameter of the exponential distribution is, as for the Poisson distribution, the $\\lambda$. \n\nUsing the cars example, an exponential distribution with $\\lambda = 10$ means that for a unit time we expect on average that a car will take $1/\\lambda = 0.1$ and with a rate of $\\lambda = 10$ events per unit time.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggcurve(fun = dexp, args = list(rate = 10)) +\n    geom_vline(xintercept = 1/10)\n```\n\n::: {.cell-output-display}\n![](understanding-gamma_files/figure-html/unnamed-chunk-4-1.svg){fig-align='center' width=672}\n:::\n:::\n\n\n\n\nIn fact, the mean of the exponential distribution is $1/\\lambda$ because is like computing the unit time divided by the expected number of events. Unit time is 1 and the expected number of events is the rate ($\\lambda$) of the Poisson.\n\n## Gamma distribution\n\nTo sum up, the Poisson distribution describe a discrete process counting the number of independent events for a unit time with rate $\\lambda$. The Exponential distribution describe the average time taken for the first event to happen given the rate $\\lambda$.\n\nWhat about if we have more than 1 event? When $k > 1$ essentially we have a Gamma distribution.\n\n$$\nf(x; \\alpha, \\lambda) = \\frac{x^{\\alpha-1} e^{-\\lambda x} \\lambda^{\\alpha}}{\\Gamma(\\alpha)}, \\quad x > 0, \\quad \\alpha, \\lambda > 0\n$$\n\nIn this equation, $\\alpha = k$ i.e. the usually called *shape* parameter is the number of events. If we fix $\\alpha = 1$ the Gamma distribution reduces to an Exponential distribution. In practice the Exponential is a special type of Gamma with $\\alpha = 1$.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggcurve(fun = dgamma,\n        args = list(shape = 1, rate = 10))\n```\n\n::: {.cell-output-display}\n![](understanding-gamma_files/figure-html/unnamed-chunk-5-1.svg){fig-align='center' width=672}\n:::\n:::\n\n\n\n\nSticking with our example, a Gamma distribution with rate $\\lambda = 10$ and shape $\\alpha = 5$ is about the time taken for $k = 5$ events to happen given the rate of 10 events per unit time.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggcurve(fun = dgamma,\n        args = list(shape = 5, rate = 10),\n        xlim = c(0, 3))\n```\n\n::: {.cell-output-display}\n![](understanding-gamma_files/figure-html/unnamed-chunk-6-1.svg){fig-align='center' width=672}\n:::\n:::\n\n\n\n\nWe will describe better the parametrization but if the time taken for 1 events to happen given $\\lambda = 10$ is $1/\\lambda = 0.1$. The time taken for $k = 5$ events is just $\\frac{1}{\\lambda} k = \\frac{k}{\\lambda}$.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggcurve(fun = dgamma,\n        args = list(shape = 5, rate = 10),\n        xlim = c(0, 3)) +\n        geom_vline(xintercept = 1/10 * 5)\n```\n\n::: {.cell-output-display}\n![](understanding-gamma_files/figure-html/unnamed-chunk-7-1.svg){fig-align='center' width=672}\n:::\n:::\n\n\n\n\nSo the Gamma is just the sum of $k$ independent exponential distributions.\n\n> Clearly, we can model whatever process respect the assumptions and not only time. But this is the natural intepretation given the link between Poisson, Exponential and Gamma.\n\nThe problem is that when we have situation not directly related to time and poisson processes is less intuitive to think as in previous examples. For this reason we can use different type of Gamma parametrization. This is the main reason why the Gamma is so confusing because there are multiple parametrizations.\n\n### Shape $\\alpha$ and Rate $\\lambda$ parametrization\n\nThis is the parametrization that we discussed above. The properties of the Gamma distribution using this approach are:\n\n- mean: $\\mu = \\frac{\\alpha}{\\lambda}$\n- variance: $\\sigma^2 = \\frac{\\alpha}{\\lambda^2}$ (similar to the Poisson)\n- standard deviation: $\\sigma = \\frac{\\sqrt{\\alpha}}{\\lambda}$\n- skewness: $\\frac{2}{\\sqrt{\\alpha}}$\n\nNotice some important aspects:\n\n- as for the Poisson, mean and standard deviations are linked. When $\\mu = \\frac{\\alpha}{\\lambda}$ increase also $\\sigma = \\frac{\\sqrt{\\alpha}}{\\lambda}$ increase\n- the relationship between mean and standard deviation is linear for the Poisson but not linear for the Gamma.\n\n### Shape $\\alpha$ and Scale $\\theta$ parametrization\n\nThis is similar to the parametrizatio above but the scale parameter is defined as the reciprocal of the rate parameter thus $\\theta = 1/\\lambda$.\n\n- mean: $\\mu = \\alpha\\theta$\n- variance: $\\sigma^2 = \\alpha\\theta^2$\n- standard deviation: $\\sigma = \\sqrt{\\alpha}\\theta$\n- skewness: $\\frac{2}{\\sqrt{\\alpha}}$\n\n### $\\mu$ and shape $\\alpha$ parametrization\n\nThis is probably the most useful at least for modelling. In fact, in R thge default when dealing with the Gamma distribution per-se (`dgamma`, `rgamma`, etc.) is using the two parametrization above. While when fitting a GLM with a Gamma distribution the `glm` (but also `glmer`) function use the $\\mu$ and shape $\\alpha$ parametrization.\n\nWith this parametrization we need to do a little bit of math for fixing the mean and the shape and then finding the scale or rate to generate data using base R function.\n\nBut how to fix the shape? We are somehow losing the event/time logic of the beginning because we simply want a Gamma with a certain mean. A good way to think about the shape is in terms of skewness. The skewness depends only on the $\\alpha$ parameter thus we can choose our Gamma fixing the mean and the desired level of skewness. Solving the equation for $\\alpha$ we have $\\alpha = 4/s^2$ (s is skewness). Then having $\\mu$ and $\\alpha$ we can calculate $\\theta$ or $\\lambda$. For example, using $\\lambda$, $\\lambda = \\mu / \\alpha$.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"false\"}\nmu <- 100\nskew <- 1\nalpha <- 4/skew^2\nlambda <- alpha / mu\n# theta <- mu / alpha\n\ny <- rgamma(1e4, shape = alpha, rate = lambda)\nhist(y, breaks = 50)\n```\n\n::: {.cell-output-display}\n![](understanding-gamma_files/figure-html/unnamed-chunk-8-1.svg){fig-align='center' width=672}\n:::\n\n```{.r .cell-code  code-fold=\"false\"}\nmean(y)\n## [1] 99.4626\nsd(y)\n## [1] 49.24929\npsych::skew(y)\n## [1] 0.9619901\n```\n:::\n\n\n\n\nLet's fit a GLM:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"false\"}\nfit <- glm(y ~ 1, family = Gamma(link = \"log\"))\nsummary(fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = y ~ 1, family = Gamma(link = \"log\"))\n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 4.599782   0.004952     929   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for Gamma family taken to be 0.2451774)\n\n    Null deviance: 2557.8  on 9999  degrees of freedom\nResidual deviance: 2557.8  on 9999  degrees of freedom\nAIC: 104612\n\nNumber of Fisher Scoring iterations: 4\n```\n\n\n:::\n:::\n\n\n\n\nGiven that we used the `log` link function, $e^{\\beta_0}$ is $\\mu$ and $\\alpha = 1/\\zeta$ where $\\zeta$ is the estimated dispersion parameter.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"false\"}\nexp(coef(fit)) # mean\n## (Intercept) \n##     99.4626\nzeta <- summary(fit)$dispersion\n1/zeta # alpha, shape\n## [1] 4.07868\n```\n:::\n\n\n\n\nAn important point that is not always clear is that the assumption of a standard glm model fitted with `glm` or `glmer` is that the shape parameter is the same for each observation. This is similar to a standard model where the residual variance is the same for each observation.\n\nThis can be relaxed using a so-called scale-location model (e.g., using `brms`) with predictors on the mean (as `glm`) and the shape parameters.\n\n### $\\mu$ and $\\sigma^2$ parametrization\n\nIn this case, we fix the $\\mu$ and $\\sigma^2$ but we have no control on the skewness.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"false\"}\nggamma(mean = c(500, 600), sd = c(200, 200))\n```\n\n::: {.cell-output-display}\n![](understanding-gamma_files/figure-html/unnamed-chunk-11-1.svg){fig-align='center' width=672}\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"false\"}\ngammap(mean = 500, sd = 200)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$shape\n[1] 6.25\n\n$rate\n[1] 0.0125\n\n$scale\n[1] 80\n\n$cv\n[1] 0.4\n\n$skew\n[1] 0.8\n\n$mean\n[1] 500\n\n$sd\n[1] 200\n```\n\n\n:::\n:::\n\n\n\n\nIn addition, let's assume we want to simulate two groups with different mean and same variance as the plot above:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"false\"}\ngammap(mean = c(500, 600), sd = c(200, 200))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$shape\n[1] 6.25 9.00\n\n$rate\n[1] 0.0125 0.0150\n\n$scale\n[1] 80.00000 66.66667\n\n$cv\n[1] 0.4000000 0.3333333\n\n$skew\n[1] 0.8000000 0.6666667\n\n$mean\n[1] 500 600\n\n$sd\n[1] 200 200\n```\n\n\n:::\n:::\n\n\n\n\nThe shape is different between the two groups, and this is a violation of the assumption of the standard GLM similary to having different residual variances between conditions.\n\nIn fact, when we model this dataset with a GLM, the shape is not recovered:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"false\"}\npars <- gammap(mean = c(500, 600), sd = c(200, 200))\nn <- 1e3\ng0 <- rgamma(n, shape = pars$shape[1], scale = pars$scale[1])\ng1 <- rgamma(n, shape = pars$shape[2], scale = pars$scale[2])\n\ny <- c(g0, g1)\nx <- rep(0:1, each = n)\n\nfit <- glm(y ~ x, family = Gamma(link = \"log\"))\nsummary(fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = y ~ x, family = Gamma(link = \"log\"))\n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  6.22003    0.01152  539.77   <2e-16 ***\nx            0.16309    0.01630   10.01   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for Gamma family taken to be 0.13279)\n\n    Null deviance: 285.59  on 1999  degrees of freedom\nResidual deviance: 272.30  on 1998  degrees of freedom\nAIC: 26673\n\nNumber of Fisher Scoring iterations: 4\n```\n\n\n:::\n:::\n\n\n\n\nThe mean shift is correctly recovered:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"false\"}\n# ~ mean g0\nexp(coef(fit)[1])\n## (Intercept) \n##    502.7173\n\n# ~ mean g1\nexp(coef(fit)[1] + coef(fit)[2])\n## (Intercept) \n##    591.7712\n\n# ~ ratio\nexp(coef(fit)[2]) # 600/500 = 1.2\n##        x \n## 1.177145\n```\n:::\n\n\n\n\nBut the dispersion is not recovered:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"false\"}\nzeta <- summary(fit)$dispersion\n1/zeta # alpha, shape\n## [1] 7.530687\nmean(pars$shape) # ~ maybe\n## [1] 7.625\n```\n:::\n\n\n\n\n## Different packages\n\n### `brms`\n\n`brms` use a mean-shape parametrization, especially when using a location-scale (i.e., distributional) model.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"false\"}\nlibrary(brms)\n\nset.seed(2025)\n\npp <- gammap(mean = 100, sd =  50)\npp\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$shape\n[1] 4\n\n$rate\n[1] 0.04\n\n$scale\n[1] 25\n\n$cv\n[1] 0.5\n\n$skew\n[1] 1\n\n$mean\n[1] 100\n\n$sd\n[1] 50\n```\n\n\n:::\n\n```{.r .cell-code  code-fold=\"false\"}\ny <- rgamma(100, shape = pp$shape, scale = pp$scale)\ndat <- data.frame(y = y)\nfit_brm <- brm(y ~ 1, family = Gamma(link = \"log\"), data = dat, file = \"fit_brm.rds\")\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"false\"}\nsummary(fit_brm)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Family: gamma \n  Links: mu = log; shape = identity \nFormula: y ~ 1 \n   Data: dat (Number of observations: 100) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nRegression Coefficients:\n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept     4.59      0.05     4.49     4.69 1.00     3416     2586\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nshape     3.95      0.53     2.97     5.06 1.00     3387     2733\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n\n\n:::\n:::\n\n\n\n\nYou can use also another link for the `shape` (usually log)\n\n### `glm/glmer`\n\n`glm` or `glmer` use the $\\mu$-dispersion ($\\phi$) parametrization where dispersion is $1/\\alpha$. Using the same dataset:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfit_glm <- glm(y ~ 1, data = dat, family = Gamma(link = \"log\"))\nsummary(fit_glm)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = y ~ 1, family = Gamma(link = \"log\"), data = dat)\n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  4.58679    0.04903   93.55   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for Gamma family taken to be 0.2404142)\n\n    Null deviance: 26.262  on 99  degrees of freedom\nResidual deviance: 26.262  on 99  degrees of freedom\nAIC: 1049.5\n\nNumber of Fisher Scoring iterations: 4\n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(fit_glm)$dispersion\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.2404142\n```\n\n\n:::\n\n```{.r .cell-code}\n1/summary(fit_glm)$dispersion\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 4.159487\n```\n\n\n:::\n:::\n\n\n\n\n### `gamlss`\n\n`gamlss` is a very complete package for scale-location modelling. The package use another parametrization. Basically what in the package is called `sigma` is $\\sqrt{\\phi}$:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(gamlss)\n\nfit_gam <- gamlss(y ~ 1, data = dat, family = GA(mu.link = \"log\", sigma.link = \"identity\")) # sigma.link can be also \"log\"\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nGAMLSS-RS iteration 1: Global Deviance = 1045.458 \nGAMLSS-RS iteration 2: Global Deviance = 1045.458 \n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(fit_gam)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n******************************************************************\nFamily:  c(\"GA\", \"Gamma\") \n\nCall:  gamlss(formula = y ~ 1, family = GA(mu.link = \"log\",  \n    sigma.link = \"identity\"), data = dat) \n\nFitting method: RS() \n\n------------------------------------------------------------------\nMu link function:  log\nMu Coefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  4.58679    0.05021   91.35   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n------------------------------------------------------------------\nSigma link function:  identity\nSigma Coefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  0.50209    0.03412   14.72   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n------------------------------------------------------------------\nNo. of observations in the fit:  100 \nDegrees of Freedom for the fit:  2\n      Residual Deg. of Freedom:  98 \n                      at cycle:  2 \n \nGlobal Deviance:     1045.458 \n            AIC:     1049.458 \n            SBC:     1054.668 \n******************************************************************\n```\n\n\n:::\n\n```{.r .cell-code}\nsqrt(fit_gam$sigma.coefficients) # same as summary(fit_glm)$dispersion\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n(Intercept) \n  0.7085856 \n```\n\n\n:::\n:::\n\n\n\n\nThe variance of the Gamma is $\\sigma^2 = \\phi^2 \\mu^2$ (see `?GA()`):\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsd(dat$y)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 48.139\n```\n\n\n:::\n\n```{.r .cell-code}\n# sqrt(dispersion)\nsqrt(fit_gam$sigma.coefficients^2 * exp(coef(fit_gam))^2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n(Intercept) \n   49.29486 \n```\n\n\n:::\n:::\n\n\n\n\n## Note about the link function\n\nThe canonical link function for the Gamma is the `inverse`, while the most common is the `log`. By default, `glm` use the `inverse`. This change the parameters interpretation.\n\nThe default link for the `dispersion` is the `identity` (e.g., in `brms`) especially when there are no predictors on the shape or dispersion. With predictors, the usual link function is the `log` to avoid negative values.\n\n## Mean-Variance relationship^[from [https://civil.colorado.edu/~balajir/CVEN6833/lectures/c-czado-GLM-lectures/GammaGLM-01.pdf](https://civil.colorado.edu/~balajir/CVEN6833/lectures/c-czado-GLM-lectures/GammaGLM-01.pdf)]\n\nAn important point is the mean-variance relationship that is common to all GLMs. For example in the poisson $E[y] = \\lambda$ and $V[y] = \\lambda$.\n\nIn the Gamma distribution, for the shape-scale parametrization:\n\n$$\nE[y] = \\mu = \\alpha\\theta\n$$\n\n$$\nV[y] = \\sigma^2 = \\alpha\\theta^2 = \\mu\\theta\n$$\n\nThus if $\\mu$ is 100, the variance is $100\\theta$\n\nFor the shape-rate parametrization:\n\n$$\nE[y] = \\mu = \\frac{\\alpha}{\\lambda}\n$$\n\n$$\nV[y] = \\sigma^2 = \\frac{\\alpha}{\\lambda^2} = \\mu \\frac{1}{\\lambda} = \\frac{\\mu}{\\lambda}\n$$\n\nIt is very strange but the coefficient of variation defined as $\\sigma/\\mu$ depends only on $\\alpha$ (stick with the shape-scale parametrization):\n\n$$\nCV = \\frac{\\sigma^2}{\\mu} = \\frac{\\sqrt{\\alpha\\beta^2}}{\\alpha\\beta} = \\frac{1}{\\alpha}\n$$\n\n$$\n\\sigma = \\mu CV \\\\\n\\sigma = \\mu \\frac{1}{\\sqrt{\\alpha}} = \\frac{\\mu}{\\sqrt{\\alpha}}\n$$\n\nSo if the mean of the Gamma is 100, the standard deviation is $\\frac{100}{\\sqrt{\\alpha}}$\n\nEssentially, the relationship between the mean and the variance (or standard deviation) is adjustable compared to other probability distributions such as the Poisson.",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}